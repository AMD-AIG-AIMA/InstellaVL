# .env
# TODO: Put your folder path to save the checkpoints - don't-include-slash-at-the-end
CKPT_DIR="<path/to/checkpoints-folder-inside-InstellaVL> or <relative-path-to-folder-in-S3-bucket;path-after-object-name>; don't-include-slash-at-the-end"
# SYSTEM Level flags for across GPU, across CPU connectivity
LOGLEVEL=INFO
OMP_NUM_THREADS=200
HSA_FORCE_FINE_GRAIN_PCIE=1
NCCL_DEBUG=INFO
TORCH_NCCL_ASYNC_ERROR_HANDLING=1

TOKENIZERS_PARALLELISM=true
# TODO: fill in your own folder path for intermediate cache files
CACHE_DIR="<Your Cache PATH>"
DATA_CACHE='${CACHE_DIR}/data_${RANDOM}/'

# ******************************** HUGGING FACE ********************************
# TODO: Put your HuggingFace token here
# HF_TOKEN="<Your HF Token>"
HF_HOME="${CACHE_DIR}"

# ******************************* S3 Credentials *******************************
# TODO: For ONLINE mode of training (where data shards and checkpoints are loaded and saved to S3 bucket)
S3_ENDPOINT_URL="<Your S3 ENDPOINT URL>"
AWS_ACCESS_KEY_ID="<Your AWS Access Key>"
AWS_SECRET_ACCESS_KEY="<Your AWS Secret Access Key>"
BUCKET_NAME="<Your Bucket Name>"
REGION_NAME="<Your Region Name>"

# *********************************** WANDB ************************************
# TODO: Put your WANDB API Key here.
WANDB_API_KEY="<Your WANDB API Key>"

# MiOpen cache
MIOPEN_USER_DB_PATH="${CACHE_DIR}/my-miopen-cache"
MIOPEN_CUSTOM_CACHE_DIR=${MIOPEN_USER_DB_PATH}
MIOPEN_DEBUG_DISABLE_FIND_DB=1
MIOPEN_DEBUG_DISABLE_SQL_WAL=1
MIOPEN_DISABLE_CACHE=true

# ***************************** Model Specifics *******************************
# Set up model specifics
LLM_VERSION="amd/AMD-OLMo-1B-SFT"
LLM_VERSION_CLEAN="${LLM_VERSION//\//_}"
VISION_MODEL_VERSION="openai/clip-vit-large-patch14-336"
VISION_MODEL_VERSION_CLEAN="${VISION_MODEL_VERSION//\//_}"
PROMPT_VERSION="instella"

# ***************************** Connection Specifics *************************
master_port=2234
RDZV_ID=453
